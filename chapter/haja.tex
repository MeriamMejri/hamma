\addcontentsline{toc}{chapter}{Biographie}
\adjustmtc
\newpage
\renewcommand\bibname{Biographie}
\begin{thebibliography}{9}
\thispagestyle{MyStyle}
\bibitem{titleB1000} 
\textbf{George Box et David Cox}, statisticiens britanniques du 20e siècle, sont connus respectivement pour la transformation Box-Cox et le modèle de régression de Cox, contribuant à la stabilisation de la variance et à l'analyse de survie. Leurs travaux ont profondément influencé la statistique appliquée. \\ 
Box, G. E. P., \& Cox, D. R. (1964). An analysis of transformations. *Journal of the Royal Statistical Society: Series B (Methodological)*, 26(2), 211-252.

\bibitem{haha} 
\textbf{Iain M. Yeo et Richard A. Johnson}, statisticiens des 20e et 21e siècles, sont reconnus pour avoir co-développé la transformation Yeo-Johnson, une méthode de normalisation des données, y compris celles avec des valeurs négatives, visant à stabiliser la variance en statistique appliquée.\\
Yeo, I. K., \& Johnson, R. A. (2000). A new family of power transformations to improve normality or symmetry. *Biometrika*, 87(4), 954-959.

\bibitem{min} 
\textbf{Hermann Minkowski} (1864-1909), mathématicien de la fin du 19e et début du 20e siècles, a marqué la géométrie et la théorie de la relativité d'Einstein avec l'espace-temps de Minkowski. Il est également connu pour avoir introduit la distance de Minkowski, une généralisation des mesures de distance.\\
Minkowski, H. (1909). Raum und Zeit. *Jahresberichte der Deutschen Mathematiker-Vereinigung*, 18, 75-88.

\bibitem{euc} 
\textbf{Euclide} (300 av. J.-C.), mathématicien de l'Antiquité grecque, est considéré comme le "père de la géométrie" grâce à son ouvrage *Les Éléments*. Il est également à l'origine de la distance euclidienne, une mesure classique entre deux points dans l'espace. \\ 
URL: \url{https://plato.stanford.edu/entries/euclid/}

\bibitem{gm} 
\textbf{Léo Goodman et William Kruskal}, tous deux statisticiens américains du 20e siècle, ont marqué l'analyse des données catégorielles. Goodman est surtout reconnu pour son travail sur les tables de contingence et le coefficient de Goodman et Kruskal, tandis que Kruskal a co-développé le test non paramétrique de Kruskal-Wallis, utilisé pour comparer plusieurs groupes. \\ 
Goodman, L. A., \& Kruskal, W. H. (1954). Measures of association for cross classifications. *Journal of the American Statistical Association*, 49(268), 732-764.

\bibitem{11} 
\textbf{Samuel Shapiro et Martin Wilk}, statisticiens américains, ont conçu le test de Shapiro-Wilk pour vérifier la normalité des données, couramment utilisé avant les tests paramétriques nécessitant une distribution normale.\\
Shapiro, S. S., \& Wilk, M. B. (1965). An analysis of variance test for normality (complete samples). *Biometrika*, 52(3-4), 591-611.

\bibitem{Levene} 
\textbf{Howard Levene}, mathématicien et statisticien américain du 20e siècle, est célèbre pour avoir développé le test de Levene. Ce test, utilisé pour vérifier l'égalité des variances entre plusieurs groupes, est essentiel en amont d'analyses statistiques comme l'ANOVA.\\
Levene, H. (1960). Robust tests for equality of variances. In Olkin, I. (Ed.), *Contributions to Probability and Statistics: Essays in Honor of Harold Hotelling* (pp. 278-292). Stanford University Press.

\bibitem{t} 
\textbf{William Sealy Gosset}, statisticien britannique des 19e et 20e siècles, est connu sous le pseudonyme "Student" pour avoir développé le test t de Student. Travaillant à la brasserie Guinness, il a conçu ce test pour comparer les moyennes de deux groupes à partir de petits échantillons, dans le cadre de l'amélioration du contrôle qualité. \\ 
Student (1908). The probable error of a mean. *Biometrika*, 6(1), 1-25.

\bibitem{pearson} 
\textbf{Karl Pearson}, pionnier britannique des statistiques modernes des 19e et 20e siècles, a fondé le premier département de statistique. Il a créé le coefficient de corrélation de Pearson, une mesure essentielle de la relation linéaire entre deux variables continues.\\ 
Pearson, K. (1895). Notes on regression and inheritance in the case of two parents. *Proceedings of the Royal Society of London*, 58, 240-242.

\bibitem{U} 
\textbf{Henry Mann}, mathématicien et statisticien américain du 20e siècle, est connu pour ses contributions à la théorie des nombres et aux statistiques. Avec Donald Whitney, il a co-développé le test de Mann-Whitney, une alternative non paramétrique au test t de Student pour comparer deux groupes indépendants.\\
Mann, H. B., \& Whitney, D. R. (1947). On a test of whether one of two random variables is stochastically larger than the other. *The Annals of Mathematical Statistics*, 18(1), 50-60.

\bibitem{spearman} 
\textbf{Charles Spearman}, psychologue et statisticien britannique, est connu pour avoir développé le coefficient de corrélation de Spearman. Il est également l’auteur de la théorie bifactorielle de l'intelligence, qui propose l’existence d’un facteur général de l'intelligence (g).\\
Spearman, C. (1904). "General intelligence," objectively determined and measured. *The American Journal of Psychology*, 15(2), 201-292.

\bibitem{fisher} 
\textbf{Ronald Fisher}, biologiste, généticien et statisticien britannique, est considéré comme l'un des fondateurs des statistiques modernes. Il a développé des techniques comme l'ANOVA et le test exact de Fisher, tout en contribuant à la génétique des populations.\\
Fisher, R. A. (1925). *Statistical Methods for Research Workers*. Oliver and Boyd.

\end{thebibliography} 

